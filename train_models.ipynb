{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-09T18:59:22.910895Z",
     "start_time": "2023-07-09T18:59:19.842780Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "label_name = {}\n",
    "for index, folder in enumerate(os.listdir(f'data/train')):\n",
    "    label_name[folder] = index-1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T19:00:13.366123Z",
     "start_time": "2023-07-09T19:00:13.360199Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_paths = np.array([])\n",
    "train_labels = {}\n",
    "for folder in os.listdir('data/train'):\n",
    "    for file in os.listdir(f'data/train/{folder}'):\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "        train_paths = np.append(train_paths, np.array([f'data/train/{folder}/{file}']))\n",
    "        train_labels[f'data/train/{folder}/{file}'] = label_name[folder]\n",
    "\n",
    "validate_paths = np.array([])\n",
    "validate_labels = {}\n",
    "for folder in os.listdir('data/validation'):\n",
    "    for file in os.listdir(f'data/validation/{folder}'):\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "        validate_paths = np.append(validate_paths, np.array([f'data/validation/{folder}/{file}']))\n",
    "        validate_labels[f'data/validation/{folder}/{file}'] = label_name[folder]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T19:00:38.687827Z",
     "start_time": "2023-07-09T19:00:14.153217Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(train_paths, train_labels, batch_size=128, n_channels=3)\n",
    "validate_generator = DataGenerator(validate_paths, validate_labels, batch_size=128, n_channels=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T19:15:44.834231Z",
     "start_time": "2023-07-09T19:15:44.830066Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, GlobalMaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=(3,3), input_shape=(250,250,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    GlobalMaxPooling2D(),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T21:20:16.420839Z",
     "start_time": "2023-07-09T21:20:16.316054Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T21:20:17.223189Z",
     "start_time": "2023-07-09T21:20:17.214026Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Nie można utworzyć pliku, który już istnieje: 'models'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\psl\\lib\\os.py:223\u001B[0m, in \u001B[0;36mmakedirs\u001B[1;34m(name, mode, exist_ok)\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 223\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[0;32m    226\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[1;31mFileExistsError\u001B[0m: [WinError 183] Nie można utworzyć pliku, który już istnieje: 'models'"
     ]
    }
   ],
   "source": [
    "os.makedirs('models')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T21:20:18.546907Z",
     "start_time": "2023-07-09T21:20:18.459965Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "callback = [ModelCheckpoint(f'models/2.h5', monitor='val_loss', verbose=1, save_best_only=True), EarlyStopping(monitor='val_loss', verbose=1, patience=5)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T21:20:20.819019Z",
     "start_time": "2023-07-09T21:20:20.813483Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('models/2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7204\n",
      "Epoch 1: val_loss improved from inf to 0.48201, saving model to models\\2.h5\n",
      "468/468 [==============================] - 132s 279ms/step - loss: 0.6602 - accuracy: 0.7204 - val_loss: 0.4820 - val_accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8560\n",
      "Epoch 2: val_loss improved from 0.48201 to 0.34508, saving model to models\\2.h5\n",
      "468/468 [==============================] - 122s 261ms/step - loss: 0.3731 - accuracy: 0.8560 - val_loss: 0.3451 - val_accuracy: 0.8734\n",
      "Epoch 3/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9004\n",
      "Epoch 3: val_loss improved from 0.34508 to 0.20740, saving model to models\\2.h5\n",
      "468/468 [==============================] - 118s 253ms/step - loss: 0.2632 - accuracy: 0.9004 - val_loss: 0.2074 - val_accuracy: 0.9223\n",
      "Epoch 4/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9261\n",
      "Epoch 4: val_loss improved from 0.20740 to 0.12471, saving model to models\\2.h5\n",
      "468/468 [==============================] - 117s 250ms/step - loss: 0.2008 - accuracy: 0.9261 - val_loss: 0.1247 - val_accuracy: 0.9565\n",
      "Epoch 5/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9464\n",
      "Epoch 5: val_loss did not improve from 0.12471\n",
      "468/468 [==============================] - 127s 271ms/step - loss: 0.1466 - accuracy: 0.9464 - val_loss: 0.1261 - val_accuracy: 0.9560\n",
      "Epoch 6/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9575\n",
      "Epoch 6: val_loss improved from 0.12471 to 0.09768, saving model to models\\2.h5\n",
      "468/468 [==============================] - 125s 266ms/step - loss: 0.1195 - accuracy: 0.9575 - val_loss: 0.0977 - val_accuracy: 0.9657\n",
      "Epoch 7/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9655\n",
      "Epoch 7: val_loss did not improve from 0.09768\n",
      "468/468 [==============================] - 122s 261ms/step - loss: 0.0964 - accuracy: 0.9655 - val_loss: 0.1149 - val_accuracy: 0.9617\n",
      "Epoch 8/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9631\n",
      "Epoch 8: val_loss improved from 0.09768 to 0.07121, saving model to models\\2.h5\n",
      "468/468 [==============================] - 126s 268ms/step - loss: 0.1064 - accuracy: 0.9631 - val_loss: 0.0712 - val_accuracy: 0.9760\n",
      "Epoch 9/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9707\n",
      "Epoch 9: val_loss improved from 0.07121 to 0.06731, saving model to models\\2.h5\n",
      "468/468 [==============================] - 147s 315ms/step - loss: 0.0845 - accuracy: 0.9707 - val_loss: 0.0673 - val_accuracy: 0.9784\n",
      "Epoch 10/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9737\n",
      "Epoch 10: val_loss improved from 0.06731 to 0.05425, saving model to models\\2.h5\n",
      "468/468 [==============================] - 160s 341ms/step - loss: 0.0750 - accuracy: 0.9737 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 11: val_loss did not improve from 0.05425\n",
      "468/468 [==============================] - 150s 320ms/step - loss: 0.0635 - accuracy: 0.9780 - val_loss: 0.0724 - val_accuracy: 0.9749\n",
      "Epoch 12/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9691\n",
      "Epoch 12: val_loss did not improve from 0.05425\n",
      "468/468 [==============================] - 139s 296ms/step - loss: 0.0909 - accuracy: 0.9691 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "Epoch 13/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9756\n",
      "Epoch 13: val_loss did not improve from 0.05425\n",
      "468/468 [==============================] - 136s 291ms/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 0.0555 - val_accuracy: 0.9814\n",
      "Epoch 14/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9805\n",
      "Epoch 14: val_loss improved from 0.05425 to 0.05045, saving model to models\\2.h5\n",
      "468/468 [==============================] - 139s 296ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: 0.0504 - val_accuracy: 0.9837\n",
      "Epoch 15/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9801\n",
      "Epoch 15: val_loss did not improve from 0.05045\n",
      "468/468 [==============================] - 137s 292ms/step - loss: 0.0581 - accuracy: 0.9801 - val_loss: 0.6250 - val_accuracy: 0.7590\n",
      "Epoch 16/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9819\n",
      "Epoch 16: val_loss improved from 0.05045 to 0.04191, saving model to models\\2.h5\n",
      "468/468 [==============================] - 140s 300ms/step - loss: 0.0537 - accuracy: 0.9819 - val_loss: 0.0419 - val_accuracy: 0.9865\n",
      "Epoch 17/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9844\n",
      "Epoch 17: val_loss did not improve from 0.04191\n",
      "468/468 [==============================] - 139s 296ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 0.0505 - val_accuracy: 0.9846\n",
      "Epoch 18/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9852\n",
      "Epoch 18: val_loss did not improve from 0.04191\n",
      "468/468 [==============================] - 135s 289ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "Epoch 19/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9836\n",
      "Epoch 19: val_loss improved from 0.04191 to 0.03867, saving model to models\\2.h5\n",
      "468/468 [==============================] - 138s 294ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0387 - val_accuracy: 0.9869\n",
      "Epoch 20/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9856\n",
      "Epoch 20: val_loss improved from 0.03867 to 0.03520, saving model to models\\2.h5\n",
      "468/468 [==============================] - 139s 297ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.0352 - val_accuracy: 0.9903\n",
      "Epoch 21/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9850\n",
      "Epoch 21: val_loss did not improve from 0.03520\n",
      "468/468 [==============================] - 138s 295ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 0.0373 - val_accuracy: 0.9883\n",
      "Epoch 22/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9866\n",
      "Epoch 22: val_loss improved from 0.03520 to 0.03435, saving model to models\\2.h5\n",
      "468/468 [==============================] - 137s 293ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0343 - val_accuracy: 0.9891\n",
      "Epoch 23/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9892\n",
      "Epoch 23: val_loss improved from 0.03435 to 0.03320, saving model to models\\2.h5\n",
      "468/468 [==============================] - 135s 289ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0332 - val_accuracy: 0.9892\n",
      "Epoch 24/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9878\n",
      "Epoch 24: val_loss did not improve from 0.03320\n",
      "468/468 [==============================] - 136s 289ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0455 - val_accuracy: 0.9852\n",
      "Epoch 25/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9765\n",
      "Epoch 25: val_loss did not improve from 0.03320\n",
      "468/468 [==============================] - 141s 301ms/step - loss: 0.0731 - accuracy: 0.9765 - val_loss: 0.0398 - val_accuracy: 0.9869\n",
      "Epoch 26/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9908\n",
      "Epoch 26: val_loss improved from 0.03320 to 0.03163, saving model to models\\2.h5\n",
      "468/468 [==============================] - 124s 264ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0316 - val_accuracy: 0.9895\n",
      "Epoch 27/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9926\n",
      "Epoch 27: val_loss did not improve from 0.03163\n",
      "468/468 [==============================] - 135s 288ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 28/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9920\n",
      "Epoch 28: val_loss did not improve from 0.03163\n",
      "468/468 [==============================] - 133s 284ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.0381 - val_accuracy: 0.9879\n",
      "Epoch 29/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9902\n",
      "Epoch 29: val_loss improved from 0.03163 to 0.02571, saving model to models\\2.h5\n",
      "468/468 [==============================] - 133s 284ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0257 - val_accuracy: 0.9926\n",
      "Epoch 30/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 30: val_loss did not improve from 0.02571\n",
      "468/468 [==============================] - 133s 285ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0328 - val_accuracy: 0.9906\n",
      "Epoch 31/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 31: val_loss did not improve from 0.02571\n",
      "468/468 [==============================] - 128s 273ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0277 - val_accuracy: 0.9903\n",
      "Epoch 32/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9909\n",
      "Epoch 32: val_loss did not improve from 0.02571\n",
      "468/468 [==============================] - 129s 275ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.0568 - val_accuracy: 0.9813\n",
      "Epoch 33/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9910\n",
      "Epoch 33: val_loss did not improve from 0.02571\n",
      "468/468 [==============================] - 131s 279ms/step - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.0376 - val_accuracy: 0.9887\n",
      "Epoch 34/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 34: val_loss did not improve from 0.02571\n",
      "468/468 [==============================] - 131s 280ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.0260 - val_accuracy: 0.9922\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16ce6223d60>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=100, batch_size=128, validation_data=validate_generator, callbacks=callback)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-09T21:20:21.678287Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.h5 - 0.9879\n",
    "Conv2D(filters=16, kernel_size=(3,3), input_shape=(250,250,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "\n",
    "2.h5 - 0.9919\n",
    "    Conv2D(filters=16, kernel_size=(3,3), input_shape=(250,250,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "\n",
    "3.h5 - 0.9886\n",
    "Conv2D(filters=16, kernel_size=(3,3), input_shape=(250,250,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=1, kernel_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "\n",
    "Best model is 2.h5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "test_paths = np.array([])\n",
    "test_labels = {}\n",
    "for folder in os.listdir('data/test'):\n",
    "    for file in os.listdir(f'data/test/{folder}'):\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "        test_paths = np.append(test_paths, np.array([f'data/test/{folder}/{file}']))\n",
    "        test_labels[f'data/test/{folder}/{file}'] = label_name[folder]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(test_paths, test_labels, batch_size=128, n_channels=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 15s 257ms/step - loss: 0.0268 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.026802781969308853, 0.9919180870056152]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test performances differences when MaxPooling is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GlobalMaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=(3,3), input_shape=(250,250,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    GlobalMaxPooling2D(),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "callback = [ModelCheckpoint(f'models/2.h5', monitor='val_loss', verbose=1, save_best_only=True), EarlyStopping(monitor='val_loss', verbose=1, patience=5)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.8201\n",
      "Epoch 1: val_loss improved from inf to 0.08744, saving model to models\\2.h5\n",
      "468/468 [==============================] - 126s 266ms/step - loss: 0.4613 - accuracy: 0.8201 - val_loss: 0.0874 - val_accuracy: 0.9690\n",
      "Epoch 2/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9729\n",
      "Epoch 2: val_loss improved from 0.08744 to 0.04766, saving model to models\\2.h5\n",
      "468/468 [==============================] - 115s 246ms/step - loss: 0.0802 - accuracy: 0.9729 - val_loss: 0.0477 - val_accuracy: 0.9872\n",
      "Epoch 3/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9832\n",
      "Epoch 3: val_loss did not improve from 0.04766\n",
      "468/468 [==============================] - 114s 244ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0776 - val_accuracy: 0.9720\n",
      "Epoch 4/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9832\n",
      "Epoch 4: val_loss improved from 0.04766 to 0.02880, saving model to models\\2.h5\n",
      "468/468 [==============================] - 114s 244ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.0288 - val_accuracy: 0.9908\n",
      "Epoch 5/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9835\n",
      "Epoch 5: val_loss improved from 0.02880 to 0.02588, saving model to models\\2.h5\n",
      "468/468 [==============================] - 114s 244ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.0259 - val_accuracy: 0.9923\n",
      "Epoch 6/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9898\n",
      "Epoch 6: val_loss improved from 0.02588 to 0.02401, saving model to models\\2.h5\n",
      "468/468 [==============================] - 113s 241ms/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.0240 - val_accuracy: 0.9923\n",
      "Epoch 7/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9434\n",
      "Epoch 7: val_loss did not improve from 0.02401\n",
      "468/468 [==============================] - 118s 251ms/step - loss: 0.1854 - accuracy: 0.9434 - val_loss: 0.0631 - val_accuracy: 0.9775\n",
      "Epoch 8/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9860\n",
      "Epoch 8: val_loss did not improve from 0.02401\n",
      "468/468 [==============================] - 122s 259ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 9/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9895\n",
      "Epoch 9: val_loss did not improve from 0.02401\n",
      "468/468 [==============================] - 122s 260ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0258 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9884\n",
      "Epoch 10: val_loss did not improve from 0.02401\n",
      "468/468 [==============================] - 121s 257ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0268 - val_accuracy: 0.9910\n",
      "Epoch 11/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9903\n",
      "Epoch 11: val_loss improved from 0.02401 to 0.01717, saving model to models\\2.h5\n",
      "468/468 [==============================] - 122s 260ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0172 - val_accuracy: 0.9935\n",
      "Epoch 12/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9753\n",
      "Epoch 12: val_loss did not improve from 0.01717\n",
      "468/468 [==============================] - 119s 255ms/step - loss: 0.0968 - accuracy: 0.9753 - val_loss: 0.0216 - val_accuracy: 0.9929\n",
      "Epoch 13/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9935\n",
      "Epoch 13: val_loss improved from 0.01717 to 0.01616, saving model to models\\2.h5\n",
      "468/468 [==============================] - 121s 257ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.0162 - val_accuracy: 0.9943\n",
      "Epoch 14/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 14: val_loss did not improve from 0.01616\n",
      "468/468 [==============================] - 126s 268ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0305 - val_accuracy: 0.9895\n",
      "Epoch 15/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 15: val_loss did not improve from 0.01616\n",
      "468/468 [==============================] - 126s 268ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0258 - val_accuracy: 0.9902\n",
      "Epoch 16/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 16: val_loss did not improve from 0.01616\n",
      "468/468 [==============================] - 126s 269ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0190 - val_accuracy: 0.9941\n",
      "Epoch 17/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934\n",
      "Epoch 17: val_loss did not improve from 0.01616\n",
      "468/468 [==============================] - 136s 290ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0207 - val_accuracy: 0.9941\n",
      "Epoch 18/100\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9945\n",
      "Epoch 18: val_loss did not improve from 0.01616\n",
      "468/468 [==============================] - 136s 291ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0415 - val_accuracy: 0.9868\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16ce6f77160>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=100, batch_size=128, validation_data=validate_generator, callbacks=callback)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 14s 240ms/step - loss: 0.0404 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.04041128605604172, 0.9874730706214905]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}